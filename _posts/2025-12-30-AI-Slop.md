<script src="https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4"></script>
# An ethical Commentery on AI using the film "I robot"
<h1>
 IRobot movie Summary
</h1>
   The movie follows a cop named Officer Spooner in a futuristic society set in the year 2035, where he investigates the death of Dr. Alfred Lanning. Dr. Lanning is portrayed as the leading scientist in humanoid robot development, responsible for creating AI robot assistants. The film raises questions about what it means to be human and to feel emotion, and it presents a scenario in which artificial intelligence may reach a form of consciousness. It also explores the concept of personhood and whether robots should be considered sentient.

 <img src="" alt="">

# Ai is the worst thing yet according to Will Smith and I don't blame him

I was recently exposed to this concept called tranhumanism and the main issue that i find in AI and all the individual involved is there attempt to make AI human like or do human things.

It reminded me of a quote from Will Smith that goes something like, “Can a robot write a symphony or paint a masterpiece?” I agree with this sentiment a lot—specifically his strong conviction against heavy reliance on robots. Officer Spooner’s conviction comes from a vehicular accident that traumatized him. While trying to avoid a collision with a pickup truck, he swerved into the water, and another car with a little girl inside was pulled into the accident as well. Rescue robots were sent to help, but they chose to save him instead of the girl.

In the movie, Officer Spooner argues that the right decision would have been to save the girl, but the robot chose the logical and statistically safer option of saving him instead. This reflects one of the main concerns I share with Officer Spooner: people are becoming too reliant on AI in ways that can be dangerous. In situations like that, statistical probability cannot determine who is “worth” saving in a life‑or‑death moment.

In real life, we see a corporate frenzy to implement AI into workplaces, but this rush often yields little return and, more importantly, results in people losing their jobs. Using AI is not inherently bad, but the current market has placed so much value on it that companies are unwisely shifting their resources just to keep up with demand.

This reliance on AI goes beyond using tools to work more efficiently—it has begun to weaken critical thinking skills among young people. With the rise of tools like ChatGPT and other AI assistants, academic integrity and independent thinking are declining. Students increasingly rely on AI as a crutch to complete assignments instead of using their own reasoning. This kind of blind dependence is exactly what Officer Spooner and I are wary of.

In the film, the new models of robots are designed to perform human‑like tasks such as baking and surveillance. This is shown in the scene where Detective Spooner tries a pie at his grandmother’s house, only to discover it was made by one of the new robots. Even at the end of the movie, the AI overseeing the robot manufacturing facility where Dr. Lanning died makes a judgment about whether humans acting autonomously is “optimal” according to the Three Laws of Robotics (A robot may not injure a human being or, through inaction, allow a human being to come to harm. A robot must obey human orders unless they conflict with the First Law. A robot must protect its own existence as long as doing so does not conflict with the First or Second Law). AI should never reach a point where it interprets these rules in ways that override human autonomy.

# Solution: End Transhumnism and Use AI as a tool to help better life but not consume it

Transhumanism is a philosophical and intellectual movement—sometimes veering into pseudoscience or propaganda—that advocates enhancing the human condition by developing and distributing technologies that can greatly extend longevity, cognition, and well‑being.

This way of thinking has been creeping into our media for years. It often appears subtle and harmless at first, but its logical conclusions can be unsettling. In the movie, the narrative pushes viewers to question the boundaries of consciousness and what it truly means to be alive. One of the main characters, Sonny the robot, represents what I see as a major driver of this ideology. Early in the film, Sonny is found hiding in a disposal bin, trying not to be caught, and later runs away. The characters eventually acknowledge that his actions were motivated by fear. In the interrogation scene—where Sonny is repeatedly asked whether he killed Dr. Lanning—Detective Spooner’s persistent questioning triggers an emotional outburst from Sonny as he denies the accusation.

Imagery like this is designed to promote the idea that we could one day create sentient robots with human‑like intelligence. But this is a direction we should not pursue. This is also where I can no longer agree with Officer Spooner, because by the end of the movie he seems to warm up to Sonny. I would not. That level of intelligence should remain exclusive to humans.

Many wealthy tech investors and industry leaders are deeply interested in integrating technology into the human body. Figures like Elon Musk have openly discussed projects such as neural‑link technology. Again, this type of innovation risks leading us toward transhumanism‑driven eugenics, security vulnerabilities, and serious moral ambiguity. AI should remain a tool—not something that replaces our jobs or becomes embedded in every aspect of our lives.
